{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0506ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65263517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b7f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples:  1413\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for dirname, _, files in os.walk('D:\\captcha\\captcha\\pics'):\n",
    "  for f in files:\n",
    "    filenames = np.append(filenames, f)\n",
    "        \n",
    "num_samples = len(filenames)\n",
    "print('number of samples: ', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9897e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of our characters\n",
    "char_list = \"0123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6361f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_labels(txt):\n",
    "    # encoding each label into list of digits\n",
    "    encoded_list = []\n",
    "    for char in txt:\n",
    "        encoded_list.append(char_list.index(char))\n",
    "    \n",
    "    return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1adf3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:/captcha/captcha/pics/'\n",
    "\n",
    "# lists for training dataset\n",
    "training_img = []                    # the images for training the model\n",
    "training_txt = []                    # the labels\n",
    "train_input_length = []              # the input of LSTM part of the model\n",
    "train_label_length = []              # the label's length (4 to 7)\n",
    "train_orig_txt = []\n",
    " \n",
    "#lists for validation dataset\n",
    "valid_img = []\n",
    "valid_txt = []\n",
    "valid_input_length = []\n",
    "valid_label_length = []\n",
    "valid_orig_txt = []\n",
    " \n",
    "max_label_len = 0                    # max length for our labels (in this case 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "081f2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in filenames:\n",
    "    raw = Image.open(path + file)\n",
    "    gray = ImageOps.grayscale(raw)\n",
    "    img = np.array(gray)\n",
    "    img = np.expand_dims(img , axis = 2)\n",
    "    img = img/255.\n",
    "\n",
    "    txt = file.split('.')[0]\n",
    "\n",
    "    if len(txt) > max_label_len:\n",
    "        max_label_len = len(txt)\n",
    "    \n",
    "    # split the dataset (85% train, 15% test)\n",
    "    if np.random.rand() >= 0.85:\n",
    "        valid_orig_txt.append(txt)\n",
    "        valid_label_length.append(len(txt))\n",
    "        valid_input_length.append(75)\n",
    "        valid_img.append(img)\n",
    "        valid_txt.append(encode_to_labels(txt))\n",
    "    else:\n",
    "        train_orig_txt.append(txt)\n",
    "        train_label_length.append(len(txt))\n",
    "        train_input_length.append(75)\n",
    "        training_img.append(img)\n",
    "        training_txt.append(encode_to_labels(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a017681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images:  89\n",
      "number of validation images:  11\n"
     ]
    }
   ],
   "source": [
    "print('number of training images: ', len(training_img))\n",
    "print('number of validation images: ', len(valid_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b2957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(max_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2923bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad each output label to maximum text length\n",
    " \n",
    "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
    "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "751ca8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input with shape of height=64 and width=306\n",
    "inputs = Input(shape=(64,306,1))\n",
    " \n",
    "\n",
    "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    " \n",
    "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
    "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    " \n",
    "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
    "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
    "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
    " \n",
    "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    " \n",
    "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "conv_7 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_6)\n",
    "batch_norm_7 = BatchNormalization()(conv_7)\n",
    "pool_7 = MaxPool2D(pool_size=(2, 1))(batch_norm_7)\n",
    "\n",
    "conv_8 = Conv2D(512, (2,2), activation = 'relu')(pool_7)\n",
    " \n",
    "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_8)\n",
    " \n",
    "\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
    " \n",
    "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
    "\n",
    "# this is the model we use for our prediction(after training)\n",
    "prediction_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a88efd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    " \n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    " \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    " \n",
    " \n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0fe1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model for training\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fa4cdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 306, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 306, 64)  640         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 153, 64)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 153, 128  73856       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 76, 128)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 76, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 76, 256)  590080      ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 76, 256)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 8, 76, 512)   1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 76, 512)  2048        ['conv2d_4[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 76, 512)   2359808     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 76, 512)  2048        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 76, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 4, 76, 512)   2359808     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 76, 512)  2048        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 2, 76, 512)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 1, 75, 512)   1049088     ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 75, 512)      0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 75, 256)      656384      ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 75, 256)     394240      ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 75, 11)       2827        ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, 7)]          0           []                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['dense[0][0]',                  \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,968,203\n",
      "Trainable params: 8,965,131\n",
      "Non-trainable params: 3,072\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a813086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saeed\\AppData\\Local\\Temp\\ipykernel_21144\\2322070578.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training_txt = np.array(training_txt)\n",
      "C:\\Users\\saeed\\AppData\\Local\\Temp\\ipykernel_21144\\2322070578.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  valid_txt = np.array(valid_txt)\n"
     ]
    }
   ],
   "source": [
    "training_img = np.array(training_img)\n",
    "train_input_length = np.array(train_input_length)\n",
    "train_label_length = np.array(train_label_length)\n",
    "\n",
    "valid_img = np.array(valid_img)\n",
    "valid_input_length = np.array(valid_input_length)\n",
    "valid_label_length = np.array(valid_label_length)\n",
    "\n",
    "training_txt = np.array(training_txt)\n",
    "valid_txt = np.array(valid_txt)\n",
    "\n",
    "batch_size = 2\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bf7fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\saeed\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "45/45 [==============================] - 15s 244ms/step - loss: 28.7365 - val_loss: 16.4963\n",
      "Epoch 2/500\n",
      "45/45 [==============================] - 10s 227ms/step - loss: 15.9696 - val_loss: 16.2254\n",
      "Epoch 3/500\n",
      "45/45 [==============================] - 11s 235ms/step - loss: 15.9226 - val_loss: 16.0287\n",
      "Epoch 4/500\n",
      "45/45 [==============================] - 11s 245ms/step - loss: 15.9097 - val_loss: 17.5205\n",
      "Epoch 5/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.9455 - val_loss: 16.1620\n",
      "Epoch 6/500\n",
      "45/45 [==============================] - 11s 241ms/step - loss: 15.8549 - val_loss: 16.5196\n",
      "Epoch 7/500\n",
      "45/45 [==============================] - 11s 246ms/step - loss: 15.8678 - val_loss: 16.0898\n",
      "Epoch 8/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 15.8324 - val_loss: 16.2098\n",
      "Epoch 9/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 15.9174 - val_loss: 16.0841\n",
      "Epoch 10/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 15.8501 - val_loss: 16.1568\n",
      "Epoch 11/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 15.8384 - val_loss: 16.1636\n",
      "Epoch 12/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 15.8035 - val_loss: 16.3230\n",
      "Epoch 13/500\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 15.8223 - val_loss: 16.1005\n",
      "Epoch 14/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 15.7757 - val_loss: 16.3485\n",
      "Epoch 15/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 15.7955 - val_loss: 16.0991\n",
      "Epoch 16/500\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 15.7748 - val_loss: 16.3518\n",
      "Epoch 17/500\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 15.7499 - val_loss: 16.4230\n",
      "Epoch 18/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 15.7620 - val_loss: 16.2637\n",
      "Epoch 19/500\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 15.6702 - val_loss: 16.2215\n",
      "Epoch 20/500\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 15.7833 - val_loss: 16.2566\n",
      "Epoch 21/500\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 15.7383 - val_loss: 16.1025\n",
      "Epoch 22/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 15.7330 - val_loss: 16.3205\n",
      "Epoch 23/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 15.6889 - val_loss: 16.2389\n",
      "Epoch 24/500\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 15.7248 - val_loss: 16.1247\n",
      "Epoch 25/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 15.6863 - val_loss: 16.1962\n",
      "Epoch 26/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.6751 - val_loss: 16.0948\n",
      "Epoch 27/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.6474 - val_loss: 16.2155\n",
      "Epoch 28/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.6692 - val_loss: 16.2619\n",
      "Epoch 29/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 15.6374 - val_loss: 16.1358\n",
      "Epoch 30/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 15.6301 - val_loss: 16.2695\n",
      "Epoch 31/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 15.6438 - val_loss: 16.3771\n",
      "Epoch 32/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.6522 - val_loss: 16.0767\n",
      "Epoch 33/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.6143 - val_loss: 16.4048\n",
      "Epoch 34/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 15.6031 - val_loss: 16.1782\n",
      "Epoch 35/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 15.5721 - val_loss: 21.1338\n",
      "Epoch 36/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 15.6596 - val_loss: 16.1165\n",
      "Epoch 37/500\n",
      "45/45 [==============================] - 11s 249ms/step - loss: 15.6039 - val_loss: 16.1799\n",
      "Epoch 38/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.5622 - val_loss: 16.0763\n",
      "Epoch 39/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.5428 - val_loss: 16.2610\n",
      "Epoch 40/500\n",
      "45/45 [==============================] - 12s 278ms/step - loss: 15.5363 - val_loss: 16.2133\n",
      "Epoch 41/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 15.5044 - val_loss: 16.4971\n",
      "Epoch 42/500\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 15.4690 - val_loss: 16.2614\n",
      "Epoch 43/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.4566 - val_loss: 16.6179\n",
      "Epoch 44/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 15.4737 - val_loss: 16.2075\n",
      "Epoch 45/500\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 15.4628 - val_loss: 32.1107\n",
      "Epoch 46/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 15.5453 - val_loss: 16.6485\n",
      "Epoch 47/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 15.3986 - val_loss: 17.1859\n",
      "Epoch 48/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.5110 - val_loss: 16.1979\n",
      "Epoch 49/500\n",
      "45/45 [==============================] - 12s 257ms/step - loss: 15.3663 - val_loss: 16.3063\n",
      "Epoch 50/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 15.3184 - val_loss: 32.6904\n",
      "Epoch 51/500\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 15.4747 - val_loss: 16.9494\n",
      "Epoch 52/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 15.4853 - val_loss: 50.6685\n",
      "Epoch 53/500\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 15.4934 - val_loss: 20.1810\n",
      "Epoch 54/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 15.4485 - val_loss: 16.5658\n",
      "Epoch 55/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 15.4382 - val_loss: 16.8641\n",
      "Epoch 56/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 15.3932 - val_loss: 16.6858\n",
      "Epoch 57/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 15.3805 - val_loss: 16.6659\n",
      "Epoch 58/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 15.3321 - val_loss: 16.2209\n",
      "Epoch 59/500\n",
      "45/45 [==============================] - 11s 252ms/step - loss: 15.3031 - val_loss: 16.0802\n",
      "Epoch 60/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 15.2806 - val_loss: 17.1571\n",
      "Epoch 61/500\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 15.3015 - val_loss: 16.2518\n",
      "Epoch 62/500\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 15.2724 - val_loss: 16.3192\n",
      "Epoch 63/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 15.1717 - val_loss: 17.8461\n",
      "Epoch 64/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 15.1687 - val_loss: 16.3345\n",
      "Epoch 65/500\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 15.1338 - val_loss: 16.4278\n",
      "Epoch 66/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 15.1508 - val_loss: 17.0694\n",
      "Epoch 67/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 15.1236 - val_loss: 16.1169\n",
      "Epoch 68/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 15.1795 - val_loss: 16.5103\n",
      "Epoch 69/500\n",
      "45/45 [==============================] - 11s 253ms/step - loss: 15.1209 - val_loss: 16.3429\n",
      "Epoch 70/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 15.1404 - val_loss: 17.2189\n",
      "Epoch 71/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 15.0748 - val_loss: 17.3066\n",
      "Epoch 72/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 15.0439 - val_loss: 20.3899\n",
      "Epoch 73/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 15.4326 - val_loss: 133.2302\n",
      "Epoch 74/500\n",
      "45/45 [==============================] - 12s 256ms/step - loss: 15.1270 - val_loss: 21.4604\n",
      "Epoch 75/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 15.0619 - val_loss: 20.6898\n",
      "Epoch 76/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 14.9992 - val_loss: 17.5390\n",
      "Epoch 77/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 14.8604 - val_loss: 16.6968\n",
      "Epoch 78/500\n",
      "45/45 [==============================] - 12s 263ms/step - loss: 14.8462 - val_loss: 16.5895\n",
      "Epoch 79/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 14.9452 - val_loss: 16.5792\n",
      "Epoch 80/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 14.8196 - val_loss: 16.7524\n",
      "Epoch 81/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 14.8811 - val_loss: 16.4045\n",
      "Epoch 82/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 14.7716 - val_loss: 16.0049\n",
      "Epoch 83/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 14.6326 - val_loss: 16.3459\n",
      "Epoch 84/500\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 14.6558 - val_loss: 16.2442\n",
      "Epoch 85/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 14.7704 - val_loss: 21.6511\n",
      "Epoch 86/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 14.7293 - val_loss: 17.1974\n",
      "Epoch 87/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 14.6759 - val_loss: 16.1400\n",
      "Epoch 88/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 14.6960 - val_loss: 21.7066\n",
      "Epoch 89/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 14.6417 - val_loss: 18.2702\n",
      "Epoch 90/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 14.6509 - val_loss: 16.3954\n",
      "Epoch 91/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 14.5287 - val_loss: 16.6626\n",
      "Epoch 92/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 14.5034 - val_loss: 16.2714\n",
      "Epoch 93/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 14.3985 - val_loss: 16.2099\n",
      "Epoch 94/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 14.4701 - val_loss: 16.1491\n",
      "Epoch 95/500\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 14.3820 - val_loss: 19.1868\n",
      "Epoch 96/500\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 14.4504 - val_loss: 16.1327\n",
      "Epoch 97/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 14.3864 - val_loss: 18.3804\n",
      "Epoch 98/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 14.4261 - val_loss: 24.7919\n",
      "Epoch 99/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 14.4572 - val_loss: 22.3231\n",
      "Epoch 100/500\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 14.3679 - val_loss: 17.4702\n",
      "Epoch 101/500\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 14.4216 - val_loss: 16.1484\n",
      "Epoch 102/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 14.4101 - val_loss: 15.9811\n",
      "Epoch 103/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 14.4110 - val_loss: 16.3231\n",
      "Epoch 104/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 14.3070 - val_loss: 16.3041\n",
      "Epoch 105/500\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 14.3320 - val_loss: 16.5475\n",
      "Epoch 106/500\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 14.4331 - val_loss: 16.3567\n",
      "Epoch 107/500\n",
      "45/45 [==============================] - 12s 272ms/step - loss: 14.3047 - val_loss: 16.4125\n",
      "Epoch 108/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 14.1903 - val_loss: 26.2485\n",
      "Epoch 109/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 14.2922 - val_loss: 35.0042\n",
      "Epoch 110/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 14.2423 - val_loss: 20.1020\n",
      "Epoch 111/500\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 14.2201 - val_loss: 16.9655\n",
      "Epoch 112/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 14.1876 - val_loss: 16.6409\n",
      "Epoch 113/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 14.2622 - val_loss: 16.7821\n",
      "Epoch 114/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 14.2224 - val_loss: 16.9486\n",
      "Epoch 115/500\n",
      "45/45 [==============================] - 16s 366ms/step - loss: 14.2445 - val_loss: 16.9036\n",
      "Epoch 116/500\n",
      "45/45 [==============================] - 16s 359ms/step - loss: 14.2769 - val_loss: 17.5310\n",
      "Epoch 117/500\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 14.2818 - val_loss: 16.4613\n",
      "Epoch 118/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 14.1401 - val_loss: 16.6268\n",
      "Epoch 119/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 14.1395 - val_loss: 17.4613\n",
      "Epoch 120/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 14.4411 - val_loss: 20.0994\n",
      "Epoch 121/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 14.8317 - val_loss: 33.5473\n",
      "Epoch 122/500\n",
      "45/45 [==============================] - 12s 263ms/step - loss: 14.2468 - val_loss: 23.2409\n",
      "Epoch 123/500\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 14.2910 - val_loss: 17.8687\n",
      "Epoch 124/500\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 14.1494 - val_loss: 26.1881\n",
      "Epoch 125/500\n",
      "45/45 [==============================] - 13s 278ms/step - loss: 14.1251 - val_loss: 22.2799\n",
      "Epoch 126/500\n",
      "45/45 [==============================] - 12s 275ms/step - loss: 14.3379 - val_loss: 26.0791\n",
      "Epoch 127/500\n",
      "45/45 [==============================] - 12s 277ms/step - loss: 14.1923 - val_loss: 22.3059\n",
      "Epoch 128/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 14.0199 - val_loss: 20.4835\n",
      "Epoch 129/500\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 14.5489 - val_loss: 110.6249\n",
      "Epoch 130/500\n",
      "45/45 [==============================] - 12s 275ms/step - loss: 14.4488 - val_loss: 18.5489\n",
      "Epoch 131/500\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 14.3789 - val_loss: 16.2587\n",
      "Epoch 132/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 14.3244 - val_loss: 17.8461\n",
      "Epoch 133/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 14.2740 - val_loss: 16.6174\n",
      "Epoch 134/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 14.1728 - val_loss: 16.5897\n",
      "Epoch 135/500\n",
      "45/45 [==============================] - 12s 275ms/step - loss: 14.2311 - val_loss: 19.9811\n",
      "Epoch 136/500\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 14.4182 - val_loss: 16.4434\n",
      "Epoch 137/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 14.2110 - val_loss: 16.2668\n",
      "Epoch 138/500\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 14.1759 - val_loss: 16.3375\n",
      "Epoch 139/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 14.0889 - val_loss: 16.2245\n",
      "Epoch 140/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 14.0479 - val_loss: 16.0010\n",
      "Epoch 141/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 14.0204 - val_loss: 20.1498\n",
      "Epoch 142/500\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 14.0884 - val_loss: 19.0324\n",
      "Epoch 143/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 14.1541 - val_loss: 17.8952\n",
      "Epoch 144/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 14.0633 - val_loss: 16.2674\n",
      "Epoch 145/500\n",
      "45/45 [==============================] - 13s 301ms/step - loss: 14.0143 - val_loss: 20.7122\n",
      "Epoch 146/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 13.8845 - val_loss: 16.5685\n",
      "Epoch 147/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 13.8568 - val_loss: 18.5315\n",
      "Epoch 148/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 13.9470 - val_loss: 21.7159\n",
      "Epoch 149/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 13.8580 - val_loss: 22.3906\n",
      "Epoch 150/500\n",
      "45/45 [==============================] - 14s 323ms/step - loss: 13.9963 - val_loss: 16.4943\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 16s 346ms/step - loss: 14.0495 - val_loss: 19.5365\n",
      "Epoch 152/500\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 13.9126 - val_loss: 17.4431\n",
      "Epoch 153/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 13.9972 - val_loss: 16.3044\n",
      "Epoch 154/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 13.9489 - val_loss: 18.4009\n",
      "Epoch 155/500\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 13.7723 - val_loss: 16.5338\n",
      "Epoch 156/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 13.7748 - val_loss: 16.7164\n",
      "Epoch 157/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 14.0868 - val_loss: 22.4878\n",
      "Epoch 158/500\n",
      "45/45 [==============================] - 12s 268ms/step - loss: 13.8457 - val_loss: 19.3785\n",
      "Epoch 159/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 14.1197 - val_loss: 24.6175\n",
      "Epoch 160/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 13.9573 - val_loss: 30.2211\n",
      "Epoch 161/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 13.7244 - val_loss: 29.6265\n",
      "Epoch 162/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 13.8861 - val_loss: 17.9819\n",
      "Epoch 163/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 13.8368 - val_loss: 16.4289\n",
      "Epoch 164/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 13.7197 - val_loss: 16.2594\n",
      "Epoch 165/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 13.7914 - val_loss: 18.7788\n",
      "Epoch 166/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 13.8563 - val_loss: 16.6534\n",
      "Epoch 167/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 13.8680 - val_loss: 16.3615\n",
      "Epoch 168/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 14.0851 - val_loss: 22.5550\n",
      "Epoch 169/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 14.2701 - val_loss: 18.3049\n",
      "Epoch 170/500\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 13.9034 - val_loss: 17.8128\n",
      "Epoch 171/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 13.8559 - val_loss: 18.2789\n",
      "Epoch 172/500\n",
      "45/45 [==============================] - 12s 278ms/step - loss: 13.7883 - val_loss: 17.9790\n",
      "Epoch 173/500\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 13.7644 - val_loss: 16.7427\n",
      "Epoch 174/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 13.9423 - val_loss: 21.9844\n",
      "Epoch 175/500\n",
      "45/45 [==============================] - 14s 300ms/step - loss: 14.5925 - val_loss: 24.7296\n",
      "Epoch 176/500\n",
      "45/45 [==============================] - 11s 255ms/step - loss: 14.1250 - val_loss: 22.2524\n",
      "Epoch 177/500\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 14.0507 - val_loss: 16.9981\n",
      "Epoch 178/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 13.8549 - val_loss: 16.6676\n",
      "Epoch 179/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 13.9300 - val_loss: 16.5164\n",
      "Epoch 180/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 13.8971 - val_loss: 16.4178\n",
      "Epoch 181/500\n",
      "45/45 [==============================] - 11s 254ms/step - loss: 13.7459 - val_loss: 17.1625\n",
      "Epoch 182/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 13.7977 - val_loss: 16.6105\n",
      "Epoch 183/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 13.6087 - val_loss: 17.2448\n",
      "Epoch 184/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 13.9863 - val_loss: 18.3228\n",
      "Epoch 185/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 13.8717 - val_loss: 18.2099\n",
      "Epoch 186/500\n",
      "45/45 [==============================] - 12s 258ms/step - loss: 13.6535 - val_loss: 16.6781\n",
      "Epoch 187/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 13.9701 - val_loss: 16.8210\n",
      "Epoch 188/500\n",
      "45/45 [==============================] - 12s 260ms/step - loss: 13.5050 - val_loss: 16.2492\n",
      "Epoch 189/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 13.6883 - val_loss: 38.5019\n",
      "Epoch 190/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 13.6238 - val_loss: 16.3790\n",
      "Epoch 191/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 13.5177 - val_loss: 18.8238\n",
      "Epoch 192/500\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 13.6766 - val_loss: 18.8924\n",
      "Epoch 193/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 13.4787 - val_loss: 16.5789\n",
      "Epoch 194/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 13.4122 - val_loss: 16.4821\n",
      "Epoch 195/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 13.2456 - val_loss: 16.7932\n",
      "Epoch 196/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 13.3551 - val_loss: 17.7416\n",
      "Epoch 197/500\n",
      "45/45 [==============================] - 12s 262ms/step - loss: 13.1803 - val_loss: 16.5930\n",
      "Epoch 198/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 13.3796 - val_loss: 16.2369\n",
      "Epoch 199/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 13.1362 - val_loss: 18.8796\n",
      "Epoch 200/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 13.2420 - val_loss: 17.4467\n",
      "Epoch 201/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 13.3499 - val_loss: 16.5960\n",
      "Epoch 202/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 13.3303 - val_loss: 16.7888\n",
      "Epoch 203/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 13.1840 - val_loss: 17.0424\n",
      "Epoch 204/500\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 13.1476 - val_loss: 17.2041\n",
      "Epoch 205/500\n",
      "45/45 [==============================] - 12s 259ms/step - loss: 13.1212 - val_loss: 16.8005\n",
      "Epoch 206/500\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 13.0978 - val_loss: 18.7839\n",
      "Epoch 207/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 13.0042 - val_loss: 16.6665\n",
      "Epoch 208/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 13.0084 - val_loss: 16.9761\n",
      "Epoch 209/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 13.0070 - val_loss: 18.9292\n",
      "Epoch 210/500\n",
      "45/45 [==============================] - 12s 278ms/step - loss: 13.1430 - val_loss: 17.9020\n",
      "Epoch 211/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 13.1242 - val_loss: 17.0201\n",
      "Epoch 212/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 12.9392 - val_loss: 16.8668\n",
      "Epoch 213/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 12.8055 - val_loss: 16.7199\n",
      "Epoch 214/500\n",
      "45/45 [==============================] - 12s 261ms/step - loss: 12.8442 - val_loss: 16.9358\n",
      "Epoch 215/500\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 12.8493 - val_loss: 16.4888\n",
      "Epoch 216/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 12.8766 - val_loss: 16.8762\n",
      "Epoch 217/500\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 12.8130 - val_loss: 17.2868\n",
      "Epoch 218/500\n",
      "45/45 [==============================] - 12s 264ms/step - loss: 13.1533 - val_loss: 16.5704\n",
      "Epoch 219/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 12.8340 - val_loss: 18.0856\n",
      "Epoch 220/500\n",
      "45/45 [==============================] - 12s 265ms/step - loss: 14.9266 - val_loss: 35.4984\n",
      "Epoch 221/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 14.1799 - val_loss: 16.4245\n",
      "Epoch 222/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 13.2936 - val_loss: 15.9550\n",
      "Epoch 223/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 13.0949 - val_loss: 18.0154\n",
      "Epoch 224/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 13.1122 - val_loss: 17.2514\n",
      "Epoch 225/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 12.7690 - val_loss: 16.3691\n",
      "Epoch 226/500\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 12.8622 - val_loss: 19.4330\n",
      "Epoch 227/500\n",
      "45/45 [==============================] - 12s 269ms/step - loss: 12.6138 - val_loss: 18.9888\n",
      "Epoch 228/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 12.5645 - val_loss: 17.0114\n",
      "Epoch 229/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 12.5717 - val_loss: 22.5011\n",
      "Epoch 230/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 12.9712 - val_loss: 16.7164\n",
      "Epoch 231/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 12.9717 - val_loss: 16.2407\n",
      "Epoch 232/500\n",
      "45/45 [==============================] - 12s 263ms/step - loss: 12.5015 - val_loss: 16.9278\n",
      "Epoch 233/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 12.4763 - val_loss: 19.8609\n",
      "Epoch 234/500\n",
      "45/45 [==============================] - 12s 269ms/step - loss: 12.7168 - val_loss: 21.2959\n",
      "Epoch 235/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 12.4866 - val_loss: 20.2103\n",
      "Epoch 236/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 12.1867 - val_loss: 20.4691\n",
      "Epoch 237/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 11.7835 - val_loss: 18.2661\n",
      "Epoch 238/500\n",
      "45/45 [==============================] - 12s 267ms/step - loss: 11.8879 - val_loss: 17.8737\n",
      "Epoch 239/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 11.8868 - val_loss: 16.5296\n",
      "Epoch 240/500\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 11.6616 - val_loss: 19.8732\n",
      "Epoch 241/500\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 11.5958 - val_loss: 17.1281\n",
      "Epoch 242/500\n",
      "45/45 [==============================] - 12s 266ms/step - loss: 11.8740 - val_loss: 17.4427\n",
      "Epoch 243/500\n",
      "45/45 [==============================] - 12s 269ms/step - loss: 11.8875 - val_loss: 34.2103\n",
      "Epoch 244/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 11.4951 - val_loss: 20.4392\n",
      "Epoch 245/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 11.2984 - val_loss: 20.9560\n",
      "Epoch 246/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 11.2188 - val_loss: 19.0335\n",
      "Epoch 247/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 11.3220 - val_loss: 16.6594\n",
      "Epoch 248/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 11.2968 - val_loss: 19.3006\n",
      "Epoch 249/500\n",
      "45/45 [==============================] - 14s 305ms/step - loss: 11.2345 - val_loss: 17.2940\n",
      "Epoch 250/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 11.0413 - val_loss: 17.1615\n",
      "Epoch 251/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 11.1428 - val_loss: 18.9943\n",
      "Epoch 252/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 10.8632 - val_loss: 17.6990\n",
      "Epoch 253/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 10.7154 - val_loss: 18.1292\n",
      "Epoch 254/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 11.6486 - val_loss: 22.1913\n",
      "Epoch 255/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 11.7710 - val_loss: 20.1001\n",
      "Epoch 256/500\n",
      "45/45 [==============================] - 12s 271ms/step - loss: 11.1387 - val_loss: 19.6114\n",
      "Epoch 257/500\n",
      "45/45 [==============================] - 12s 272ms/step - loss: 10.6306 - val_loss: 17.1382\n",
      "Epoch 258/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 10.6188 - val_loss: 19.0889\n",
      "Epoch 259/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 10.5150 - val_loss: 18.8702\n",
      "Epoch 260/500\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 10.4686 - val_loss: 18.4263\n",
      "Epoch 261/500\n",
      "45/45 [==============================] - 12s 268ms/step - loss: 10.4293 - val_loss: 19.0221\n",
      "Epoch 262/500\n",
      "45/45 [==============================] - 12s 273ms/step - loss: 10.4190 - val_loss: 20.0006\n",
      "Epoch 263/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 10.3984 - val_loss: 17.8148\n",
      "Epoch 264/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 10.2607 - val_loss: 21.0785\n",
      "Epoch 265/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 11.3645 - val_loss: 17.5968\n",
      "Epoch 266/500\n",
      "45/45 [==============================] - 12s 270ms/step - loss: 10.4496 - val_loss: 21.3653\n",
      "Epoch 267/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 10.4655 - val_loss: 21.9047\n",
      "Epoch 268/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 10.2185 - val_loss: 18.5125\n",
      "Epoch 269/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 9.9568 - val_loss: 17.1290\n",
      "Epoch 270/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 9.6355 - val_loss: 18.9817\n",
      "Epoch 271/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 9.4541 - val_loss: 19.1455\n",
      "Epoch 272/500\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 9.2961 - val_loss: 19.3878\n",
      "Epoch 273/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 9.3384 - val_loss: 19.5483\n",
      "Epoch 274/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 9.5306 - val_loss: 19.1539\n",
      "Epoch 275/500\n",
      "45/45 [==============================] - 12s 275ms/step - loss: 9.3274 - val_loss: 20.7597\n",
      "Epoch 276/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 9.6845 - val_loss: 19.4946\n",
      "Epoch 277/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 9.4168 - val_loss: 21.3644\n",
      "Epoch 278/500\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 9.1661 - val_loss: 19.6511\n",
      "Epoch 279/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 8.7525 - val_loss: 22.0703\n",
      "Epoch 280/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 8.9451 - val_loss: 20.7146\n",
      "Epoch 281/500\n",
      "45/45 [==============================] - 13s 278ms/step - loss: 9.0205 - val_loss: 20.0864\n",
      "Epoch 282/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 9.2454 - val_loss: 27.7713\n",
      "Epoch 283/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 8.9895 - val_loss: 20.9547\n",
      "Epoch 284/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 9.2429 - val_loss: 21.7170\n",
      "Epoch 285/500\n",
      "45/45 [==============================] - 13s 278ms/step - loss: 8.8789 - val_loss: 23.6987\n",
      "Epoch 286/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 9.0735 - val_loss: 23.1383\n",
      "Epoch 287/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 8.5771 - val_loss: 22.4125\n",
      "Epoch 288/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 8.7613 - val_loss: 21.5198\n",
      "Epoch 289/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 9.5368 - val_loss: 23.8231\n",
      "Epoch 290/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 10.5047 - val_loss: 23.8487\n",
      "Epoch 291/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 10.0312 - val_loss: 23.5591\n",
      "Epoch 292/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 9.2182 - val_loss: 20.4906\n",
      "Epoch 293/500\n",
      "45/45 [==============================] - 12s 274ms/step - loss: 9.4438 - val_loss: 93.3324\n",
      "Epoch 294/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 9.7260 - val_loss: 85.8181\n",
      "Epoch 295/500\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 9.5758 - val_loss: 18.5133\n",
      "Epoch 296/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 9.2239 - val_loss: 22.3603\n",
      "Epoch 297/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 8.6917 - val_loss: 23.0568\n",
      "Epoch 298/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 8.4981 - val_loss: 22.0510\n",
      "Epoch 299/500\n",
      "45/45 [==============================] - 12s 278ms/step - loss: 8.2175 - val_loss: 24.4617\n",
      "Epoch 300/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 8.3843 - val_loss: 18.4618\n",
      "Epoch 301/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 8.4970 - val_loss: 20.0427\n",
      "Epoch 302/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 8.5057 - val_loss: 20.2983\n",
      "Epoch 303/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 8.9383 - val_loss: 28.8340\n",
      "Epoch 304/500\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 8.2589 - val_loss: 24.0421\n",
      "Epoch 305/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 8.2974 - val_loss: 23.7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "45/45 [==============================] - 13s 296ms/step - loss: 8.4397 - val_loss: 18.0104\n",
      "Epoch 307/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 8.1259 - val_loss: 20.1544\n",
      "Epoch 308/500\n",
      "45/45 [==============================] - 14s 303ms/step - loss: 10.8633 - val_loss: 26.4335\n",
      "Epoch 309/500\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 10.1868 - val_loss: 25.2052\n",
      "Epoch 310/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 9.5593 - val_loss: 33.4639\n",
      "Epoch 311/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 11.1756 - val_loss: 126.9798\n",
      "Epoch 312/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 11.2922 - val_loss: 18.3681\n",
      "Epoch 313/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 9.5623 - val_loss: 20.9002\n",
      "Epoch 314/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 9.9822 - val_loss: 18.5039\n",
      "Epoch 315/500\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 9.5191 - val_loss: 19.5891\n",
      "Epoch 316/500\n",
      "45/45 [==============================] - 13s 278ms/step - loss: 9.0596 - val_loss: 21.3698\n",
      "Epoch 317/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 8.7216 - val_loss: 21.6588\n",
      "Epoch 318/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 7.9508 - val_loss: 22.7965\n",
      "Epoch 319/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 7.9132 - val_loss: 23.1994\n",
      "Epoch 320/500\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 7.3131 - val_loss: 18.2835\n",
      "Epoch 321/500\n",
      "45/45 [==============================] - 12s 275ms/step - loss: 7.6529 - val_loss: 21.7959\n",
      "Epoch 322/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 7.1761 - val_loss: 24.9108\n",
      "Epoch 323/500\n",
      "45/45 [==============================] - 13s 297ms/step - loss: 6.8214 - val_loss: 21.2944\n",
      "Epoch 324/500\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 6.9166 - val_loss: 20.0122\n",
      "Epoch 325/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 7.0757 - val_loss: 21.4741\n",
      "Epoch 326/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 6.7310 - val_loss: 20.8279\n",
      "Epoch 327/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 6.5019 - val_loss: 20.6658\n",
      "Epoch 328/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 6.3395 - val_loss: 19.9332\n",
      "Epoch 329/500\n",
      "45/45 [==============================] - 14s 319ms/step - loss: 6.4013 - val_loss: 22.0365\n",
      "Epoch 330/500\n",
      "45/45 [==============================] - 12s 277ms/step - loss: 5.9780 - val_loss: 20.1502\n",
      "Epoch 331/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 5.8651 - val_loss: 20.0472\n",
      "Epoch 332/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 6.0156 - val_loss: 21.3034\n",
      "Epoch 333/500\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 5.7993 - val_loss: 20.1872\n",
      "Epoch 334/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 5.8061 - val_loss: 43.5509\n",
      "Epoch 335/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 5.7222 - val_loss: 21.5362\n",
      "Epoch 336/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 5.6775 - val_loss: 21.7831\n",
      "Epoch 337/500\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 6.1346 - val_loss: 23.0094\n",
      "Epoch 338/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 6.8191 - val_loss: 21.0797\n",
      "Epoch 339/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 6.0802 - val_loss: 23.5339\n",
      "Epoch 340/500\n",
      "45/45 [==============================] - 13s 296ms/step - loss: 6.0528 - val_loss: 22.8123\n",
      "Epoch 341/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 5.8341 - val_loss: 26.1989\n",
      "Epoch 342/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 5.6980 - val_loss: 25.3103\n",
      "Epoch 343/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 5.4825 - val_loss: 24.4748\n",
      "Epoch 344/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 5.4117 - val_loss: 22.6107\n",
      "Epoch 345/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 5.4265 - val_loss: 20.7015\n",
      "Epoch 346/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 5.2039 - val_loss: 25.1216\n",
      "Epoch 347/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 5.3219 - val_loss: 24.6186\n",
      "Epoch 348/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 5.5585 - val_loss: 20.7984\n",
      "Epoch 349/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 5.3322 - val_loss: 22.2842\n",
      "Epoch 350/500\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 4.9916 - val_loss: 21.0810\n",
      "Epoch 351/500\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 5.6219 - val_loss: 25.7858\n",
      "Epoch 352/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 6.4026 - val_loss: 25.3310\n",
      "Epoch 353/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 6.2170 - val_loss: 22.8966\n",
      "Epoch 354/500\n",
      "45/45 [==============================] - 14s 307ms/step - loss: 6.7480 - val_loss: 22.3630\n",
      "Epoch 355/500\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 7.2178 - val_loss: 23.3306\n",
      "Epoch 356/500\n",
      "45/45 [==============================] - 16s 348ms/step - loss: 6.3857 - val_loss: 21.9162\n",
      "Epoch 357/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 5.8155 - val_loss: 35.0808\n",
      "Epoch 358/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 5.4559 - val_loss: 21.6924\n",
      "Epoch 359/500\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 5.0464 - val_loss: 21.6177\n",
      "Epoch 360/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 5.0688 - val_loss: 24.5087\n",
      "Epoch 361/500\n",
      "45/45 [==============================] - 14s 300ms/step - loss: 5.2366 - val_loss: 25.2044\n",
      "Epoch 362/500\n",
      "45/45 [==============================] - 12s 276ms/step - loss: 5.0888 - val_loss: 24.4833\n",
      "Epoch 363/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 4.9724 - val_loss: 24.0387\n",
      "Epoch 364/500\n",
      "45/45 [==============================] - 14s 317ms/step - loss: 4.8099 - val_loss: 25.8928\n",
      "Epoch 365/500\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 4.5579 - val_loss: 23.0790\n",
      "Epoch 366/500\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 4.2638 - val_loss: 23.9330\n",
      "Epoch 367/500\n",
      "45/45 [==============================] - 14s 311ms/step - loss: 9.6431 - val_loss: 23.9334\n",
      "Epoch 368/500\n",
      "45/45 [==============================] - 16s 347ms/step - loss: 7.8715 - val_loss: 23.2155\n",
      "Epoch 369/500\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 6.3216 - val_loss: 24.9343\n",
      "Epoch 370/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 6.2426 - val_loss: 21.9413\n",
      "Epoch 371/500\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 5.7293 - val_loss: 21.4304\n",
      "Epoch 372/500\n",
      "45/45 [==============================] - 16s 350ms/step - loss: 4.9850 - val_loss: 22.6886\n",
      "Epoch 373/500\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 4.4736 - val_loss: 22.2059\n",
      "Epoch 374/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 4.8438 - val_loss: 23.8687\n",
      "Epoch 375/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 5.1950 - val_loss: 22.3934\n",
      "Epoch 376/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 4.2464 - val_loss: 22.3421\n",
      "Epoch 377/500\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 3.9712 - val_loss: 24.9948\n",
      "Epoch 378/500\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 4.7600 - val_loss: 26.9783\n",
      "Epoch 379/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 5.1574 - val_loss: 24.0229\n",
      "Epoch 380/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 3.8227 - val_loss: 24.1460\n",
      "Epoch 381/500\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 3.7473 - val_loss: 21.8932\n",
      "Epoch 382/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 3.5377 - val_loss: 23.4314\n",
      "Epoch 383/500\n",
      "45/45 [==============================] - 13s 278ms/step - loss: 3.2938 - val_loss: 23.1596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 3.4022 - val_loss: 23.7068\n",
      "Epoch 385/500\n",
      "45/45 [==============================] - 13s 299ms/step - loss: 3.4565 - val_loss: 24.2820\n",
      "Epoch 386/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 3.1413 - val_loss: 23.2759\n",
      "Epoch 387/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 3.3026 - val_loss: 22.4094\n",
      "Epoch 388/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 3.0458 - val_loss: 25.1265\n",
      "Epoch 389/500\n",
      "45/45 [==============================] - 13s 296ms/step - loss: 3.0416 - val_loss: 22.8285\n",
      "Epoch 390/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 3.2137 - val_loss: 26.2163\n",
      "Epoch 391/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 3.6832 - val_loss: 24.6392\n",
      "Epoch 392/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 3.8528 - val_loss: 23.4235\n",
      "Epoch 393/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 3.2290 - val_loss: 25.4250\n",
      "Epoch 394/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 2.8559 - val_loss: 25.2463\n",
      "Epoch 395/500\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 2.8121 - val_loss: 26.5854\n",
      "Epoch 396/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 2.5226 - val_loss: 24.4023\n",
      "Epoch 397/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 2.6452 - val_loss: 25.7693\n",
      "Epoch 398/500\n",
      "45/45 [==============================] - 14s 301ms/step - loss: 2.5964 - val_loss: 26.7756\n",
      "Epoch 399/500\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 2.4645 - val_loss: 27.6235\n",
      "Epoch 400/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 2.3939 - val_loss: 25.9790\n",
      "Epoch 401/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 2.2362 - val_loss: 26.1266\n",
      "Epoch 402/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 2.4817 - val_loss: 29.7591\n",
      "Epoch 403/500\n",
      "45/45 [==============================] - 14s 321ms/step - loss: 3.2448 - val_loss: 27.1678\n",
      "Epoch 404/500\n",
      "45/45 [==============================] - 15s 335ms/step - loss: 3.0720 - val_loss: 40.8988\n",
      "Epoch 405/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 2.6856 - val_loss: 26.8441\n",
      "Epoch 406/500\n",
      "45/45 [==============================] - 13s 282ms/step - loss: 2.1062 - val_loss: 26.6651\n",
      "Epoch 407/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 2.7747 - val_loss: 26.8017\n",
      "Epoch 408/500\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 2.8470 - val_loss: 28.5616\n",
      "Epoch 409/500\n",
      "45/45 [==============================] - 14s 314ms/step - loss: 2.6907 - val_loss: 32.3078\n",
      "Epoch 410/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 2.5371 - val_loss: 28.3857\n",
      "Epoch 411/500\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 1.9092 - val_loss: 26.1660\n",
      "Epoch 412/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 1.8682 - val_loss: 27.2197\n",
      "Epoch 413/500\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 1.7636 - val_loss: 28.3369\n",
      "Epoch 414/500\n",
      "45/45 [==============================] - 13s 283ms/step - loss: 1.7338 - val_loss: 27.8832\n",
      "Epoch 415/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 2.3618 - val_loss: 24.5019\n",
      "Epoch 416/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 2.4507 - val_loss: 27.8733\n",
      "Epoch 417/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 2.2063 - val_loss: 27.6109\n",
      "Epoch 418/500\n",
      "45/45 [==============================] - 14s 309ms/step - loss: 2.3176 - val_loss: 28.8344\n",
      "Epoch 419/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 3.1811 - val_loss: 26.8665\n",
      "Epoch 420/500\n",
      "45/45 [==============================] - 13s 296ms/step - loss: 2.4215 - val_loss: 31.0034\n",
      "Epoch 421/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 2.2002 - val_loss: 26.8961\n",
      "Epoch 422/500\n",
      "45/45 [==============================] - 15s 322ms/step - loss: 2.1289 - val_loss: 29.0503\n",
      "Epoch 423/500\n",
      "45/45 [==============================] - 13s 281ms/step - loss: 3.0516 - val_loss: 29.4421\n",
      "Epoch 424/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 3.4269 - val_loss: 31.5626\n",
      "Epoch 425/500\n",
      "45/45 [==============================] - 14s 320ms/step - loss: 3.1174 - val_loss: 31.6958\n",
      "Epoch 426/500\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 2.8961 - val_loss: 27.4938\n",
      "Epoch 427/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 4.5352 - val_loss: 38.2998\n",
      "Epoch 428/500\n",
      "45/45 [==============================] - 13s 287ms/step - loss: 5.7534 - val_loss: 34.6888\n",
      "Epoch 429/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 5.0900 - val_loss: 31.5573\n",
      "Epoch 430/500\n",
      "45/45 [==============================] - 15s 329ms/step - loss: 3.2094 - val_loss: 28.8130\n",
      "Epoch 431/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 3.1793 - val_loss: 35.0384\n",
      "Epoch 432/500\n",
      "45/45 [==============================] - 13s 279ms/step - loss: 3.0527 - val_loss: 26.6911\n",
      "Epoch 433/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 2.3866 - val_loss: 27.0179\n",
      "Epoch 434/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 2.0882 - val_loss: 28.0156\n",
      "Epoch 435/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 1.7433 - val_loss: 26.9389\n",
      "Epoch 436/500\n",
      "45/45 [==============================] - 13s 280ms/step - loss: 1.5296 - val_loss: 28.1596\n",
      "Epoch 437/500\n",
      "45/45 [==============================] - 13s 284ms/step - loss: 1.4049 - val_loss: 28.0944\n",
      "Epoch 438/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 1.1753 - val_loss: 28.2921\n",
      "Epoch 439/500\n",
      "45/45 [==============================] - 14s 318ms/step - loss: 1.1373 - val_loss: 26.9002\n",
      "Epoch 440/500\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 1.1139 - val_loss: 28.2651\n",
      "Epoch 441/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 1.0120 - val_loss: 28.4578\n",
      "Epoch 442/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 1.0214 - val_loss: 29.0017\n",
      "Epoch 443/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 0.8801 - val_loss: 27.8103\n",
      "Epoch 444/500\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 0.9040 - val_loss: 29.1862\n",
      "Epoch 445/500\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 0.8496 - val_loss: 27.5057\n",
      "Epoch 446/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 0.9017 - val_loss: 28.9724\n",
      "Epoch 447/500\n",
      "45/45 [==============================] - 13s 291ms/step - loss: 0.8051 - val_loss: 28.0534\n",
      "Epoch 448/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 0.7411 - val_loss: 27.8900\n",
      "Epoch 449/500\n",
      "45/45 [==============================] - 15s 336ms/step - loss: 0.7972 - val_loss: 30.1629\n",
      "Epoch 450/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 0.7070 - val_loss: 29.7463\n",
      "Epoch 451/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 1.1364 - val_loss: 30.2225\n",
      "Epoch 452/500\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 1.1418 - val_loss: 30.1494\n",
      "Epoch 453/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.9344 - val_loss: 32.7270\n",
      "Epoch 454/500\n",
      "45/45 [==============================] - 15s 332ms/step - loss: 0.7936 - val_loss: 27.8267\n",
      "Epoch 455/500\n",
      "45/45 [==============================] - 14s 302ms/step - loss: 0.8613 - val_loss: 28.3922\n",
      "Epoch 456/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 1.0809 - val_loss: 31.3611\n",
      "Epoch 457/500\n",
      "45/45 [==============================] - 14s 306ms/step - loss: 0.9849 - val_loss: 32.9362\n",
      "Epoch 458/500\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 0.9991 - val_loss: 30.9434\n",
      "Epoch 459/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 0.9888 - val_loss: 30.9332\n",
      "Epoch 460/500\n",
      "45/45 [==============================] - 13s 294ms/step - loss: 0.8406 - val_loss: 31.7013\n",
      "Epoch 461/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 1.0241 - val_loss: 30.5773\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 15s 328ms/step - loss: 0.8611 - val_loss: 31.0453\n",
      "Epoch 463/500\n",
      "45/45 [==============================] - 14s 313ms/step - loss: 1.1791 - val_loss: 33.9891\n",
      "Epoch 464/500\n",
      "45/45 [==============================] - 13s 285ms/step - loss: 2.1179 - val_loss: 28.8516\n",
      "Epoch 465/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 1.7194 - val_loss: 30.4291\n",
      "Epoch 466/500\n",
      "45/45 [==============================] - 14s 316ms/step - loss: 1.2862 - val_loss: 28.8306\n",
      "Epoch 467/500\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 1.2164 - val_loss: 28.9433\n",
      "Epoch 468/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 1.5621 - val_loss: 29.6008\n",
      "Epoch 469/500\n",
      "45/45 [==============================] - 13s 288ms/step - loss: 2.1707 - val_loss: 31.6458\n",
      "Epoch 470/500\n",
      "45/45 [==============================] - 14s 310ms/step - loss: 2.8738 - val_loss: 28.8728\n",
      "Epoch 471/500\n",
      "45/45 [==============================] - 15s 333ms/step - loss: 3.5165 - val_loss: 29.4709\n",
      "Epoch 472/500\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 3.7246 - val_loss: 37.9773\n",
      "Epoch 473/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 2.7191 - val_loss: 32.1578\n",
      "Epoch 474/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 1.8649 - val_loss: 35.3053\n",
      "Epoch 475/500\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 1.5653 - val_loss: 36.6224\n",
      "Epoch 476/500\n",
      "45/45 [==============================] - 15s 337ms/step - loss: 4.7811 - val_loss: 30.6286\n",
      "Epoch 477/500\n",
      "45/45 [==============================] - 13s 290ms/step - loss: 6.6563 - val_loss: 130.0616\n",
      "Epoch 478/500\n",
      "45/45 [==============================] - 13s 293ms/step - loss: 9.0544 - val_loss: 28.2339\n",
      "Epoch 479/500\n",
      "45/45 [==============================] - 13s 300ms/step - loss: 5.9212 - val_loss: 30.3542\n",
      "Epoch 480/500\n",
      "45/45 [==============================] - 15s 331ms/step - loss: 5.8079 - val_loss: 30.7779\n",
      "Epoch 481/500\n",
      "45/45 [==============================] - 15s 324ms/step - loss: 5.6271 - val_loss: 30.2498\n",
      "Epoch 482/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 4.0202 - val_loss: 30.5583\n",
      "Epoch 483/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 4.7616 - val_loss: 31.2489\n",
      "Epoch 484/500\n",
      "45/45 [==============================] - 15s 325ms/step - loss: 4.5677 - val_loss: 30.4242\n",
      "Epoch 485/500\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 3.0194 - val_loss: 34.1180\n",
      "Epoch 486/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 2.7756 - val_loss: 33.4591\n",
      "Epoch 487/500\n",
      "45/45 [==============================] - 14s 304ms/step - loss: 2.4274 - val_loss: 30.4096\n",
      "Epoch 488/500\n",
      "45/45 [==============================] - 16s 356ms/step - loss: 2.1354 - val_loss: 29.4458\n",
      "Epoch 489/500\n",
      "45/45 [==============================] - 15s 328ms/step - loss: 2.1138 - val_loss: 30.2751\n",
      "Epoch 490/500\n",
      "45/45 [==============================] - 13s 286ms/step - loss: 1.8642 - val_loss: 28.9194\n",
      "Epoch 491/500\n",
      "45/45 [==============================] - 13s 292ms/step - loss: 1.6300 - val_loss: 29.1658\n",
      "Epoch 492/500\n",
      "45/45 [==============================] - 15s 326ms/step - loss: 1.7735 - val_loss: 28.8670\n",
      "Epoch 493/500\n",
      "45/45 [==============================] - 16s 351ms/step - loss: 1.6978 - val_loss: 29.1048\n",
      "Epoch 494/500\n",
      "45/45 [==============================] - 14s 315ms/step - loss: 2.0213 - val_loss: 30.1377\n",
      "Epoch 495/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 2.2402 - val_loss: 29.3855\n",
      "Epoch 496/500\n",
      "45/45 [==============================] - 14s 308ms/step - loss: 1.6899 - val_loss: 31.8749\n",
      "Epoch 497/500\n",
      "45/45 [==============================] - 15s 342ms/step - loss: 2.1107 - val_loss: 31.3409\n",
      "Epoch 498/500\n",
      "45/45 [==============================] - 16s 367ms/step - loss: 1.3692 - val_loss: 32.2373\n",
      "Epoch 499/500\n",
      "45/45 [==============================] - 13s 289ms/step - loss: 1.7101 - val_loss: 27.9897\n",
      "Epoch 500/500\n",
      "45/45 [==============================] - 13s 295ms/step - loss: 2.3590 - val_loss: 31.6486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b9692ea90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length],\n",
    "          y=np.zeros(len(training_img)),\n",
    "          batch_size=batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]),\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934d3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights_V1_100data.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce6dd069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "original_text =   0891051\n",
      "predicted text = 38450\n",
      "\n",
      "original_text =   1168658\n",
      "predicted text = 785528\n",
      "\n",
      "original_text =   138073\n",
      "predicted text = 40878\n",
      "\n",
      "original_text =   227341\n",
      "predicted text = 788570\n",
      "\n",
      "original_text =   649788\n",
      "predicted text = 5828\n",
      "\n",
      "original_text =   69822\n",
      "predicted text = 77411\n",
      "\n",
      "original_text =   70209\n",
      "predicted text = 10150\n",
      "\n",
      "original_text =   8054393\n",
      "predicted text = 8833926\n",
      "\n",
      "original_text =   813317\n",
      "predicted text = 2332070\n",
      "\n",
      "original_text =   9682858\n",
      "predicted text = 6238888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the model weights\n",
    "prediction_model.load_weights('model_weights_V1_100data.hdf5')\n",
    "\n",
    "# predict outputs on validation images\n",
    "prediction = prediction_model.predict(valid_img[:10])\n",
    "\n",
    "# use CTC decoder\n",
    "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
    "                         greedy=True)[0][0])\n",
    " \n",
    "# see the results\n",
    "i = 0\n",
    "for x in out:\n",
    "    print(\"original_text =  \", valid_orig_txt[i])\n",
    "    print(\"predicted text = \", end = '')\n",
    "    for p in x:  \n",
    "        if int(p) != -1:\n",
    "            print(char_list[int(p)], end = '')       \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0681553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
